{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c91682-4613-484f-a3d5-bb75dff20c8d",
   "metadata": {},
   "source": [
    "## Retrieval of PRISM Precipitation Data for a Watershed of Interest\n",
    "\n",
    "**Authors**:  \n",
    "- Irene Garousi-Nejad <igarousi@cuahsi.org>\n",
    "\n",
    "**Last Updated**: 05.08.2023\n",
    "\n",
    "**Description**: \n",
    "    \n",
    "This notebook fetches PRISM precipitation data and extracts a subset for a specific region using the spatial extent provided by the watershed shapefile. The output will be a CSV file containing the monthly normal precipitation data, with a spatial resolution of 800, averaged spatially across the watershed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bbe53-e8be-4eb8-93a2-16cba8949f9d",
   "metadata": {},
   "source": [
    "TODO: update the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0674a-c7e8-4727-8e94-d685675d2d30",
   "metadata": {},
   "source": [
    "![watershed](https://www.hydroshare.org/resource/b1379f00121e456f958f9e22e913aa8a/data/contents/case-study-logan-river-watershed.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1761204e-ddcd-4605-976d-2fbe07cd8aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the following libraries\n",
    "# make sure the kernel is set to conda env: iguide\n",
    "!pip install cartopy --quiet\n",
    "!pip install rasterstats --quiet\n",
    "!pip install geopandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b9646-6131-4457-9d35-b57a64238c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import rasterio as rio\n",
    "from rasterstats import zonal_stats\n",
    "from geopandas import GeoSeries, GeoDataFrame, read_file, gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from shapely.geometry import MultiPolygon\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e12839-7bde-4544-a791-f601caa7ef18",
   "metadata": {},
   "source": [
    "## 1. Load the Watershed of Interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff80ef7-2689-4e61-85d6-084b745bae36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the watershed\n",
    "mp = MultiPolygon(Reader('./GISBasins/WeberRiverBasin.shp').geometries())\n",
    "\n",
    "# read the geometries for plotting\n",
    "shape_feature = ShapelyFeature(mp.geoms,\n",
    "                                ccrs.PlateCarree(), facecolor='none')\n",
    "\n",
    "# visualize data on the map\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "\n",
    "shape_feature = ShapelyFeature(mp.geoms,\n",
    "                                ccrs.PlateCarree(), facecolor='none')\n",
    "ax.add_feature(shape_feature, zorder=1)\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--');\n",
    "\n",
    "# modify the x and y limits based on the watershed's bounding box information\n",
    "ax.set_ylim([40.5, 41.5]);\n",
    "ax.set_xlim([-112.35, -110.75]);\n",
    "ax.set_aspect('equal');\n",
    "ax.coastlines();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001fddf-bc97-4667-b8fe-2199ae0623ff",
   "metadata": {},
   "source": [
    "The watershed of interest contains seven HUC8 catchments. If we apply the `zonal_stats` function from the `rasterstats` library to this shapefile containing multiple geometries, the function calculates statistics separately for each individual geometry. However, in our case, we want to compute statistics for the entire watershed rather than for each individual catchment. To achieve this, we need to dissolve the multiple catchments into a single feature. By dissolving the geometries, we will merge them together to create a single polygon representing the entire watershed. This will allow us to calculate the desired statistics for the watershed as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd0a9cc-519b-41a5-8c19-07e6d5be0a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data as a dataframe\n",
    "watershed = read_file('./GISBasins/WeberRiverBasin.shp')\n",
    "\n",
    "# add a column with a constant value that will be used to dissolve the shapefile\n",
    "watershed['temp']=1\n",
    "\n",
    "# dissolve\n",
    "watershed_dis = watershed.dissolve(by = 'temp', aggfunc = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67b1e2-266c-4264-a11e-9df7059155bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "watershed_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11ab59-8455-43b6-9914-67828c38421f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the geometries for plotting\n",
    "shape_feature = ShapelyFeature(watershed_dis.geometry,\n",
    "                                ccrs.PlateCarree(), facecolor='none')\n",
    "\n",
    "# visualize data on the map\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "\n",
    "shape_feature = ShapelyFeature( watershed_dis.geometry,\n",
    "                                ccrs.PlateCarree(), facecolor='none')\n",
    "ax.add_feature(shape_feature, zorder=1)\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--');\n",
    "\n",
    "# modify the x and y limits based on the watershed's bounding box information\n",
    "ax.set_ylim([40.5, 41.5]);\n",
    "ax.set_xlim([-112.35, -110.75]);\n",
    "ax.set_aspect('equal');\n",
    "ax.coastlines();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25656a91-6aea-45e6-a740-bb0fe7926237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gdalinfo ./GISBasins/WeberRiverBasin.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6a14-143d-4612-be1d-677f3f92a0ad",
   "metadata": {},
   "source": [
    "## 2. Download PRISM Monthly Normals Precipitation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e40119-2c87-432f-b350-a82617432118",
   "metadata": {},
   "source": [
    "The PRISM web service provides a single file (i.e., grids in BIL format) per request. We will run the following bash script to perform a bulk download of multiple grid files. This downloads PRISM precipitation data (`ppt`) and saves these files into PRISM_monthly_normals. The results are *_bil.zip. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ee51c-e06c-410c-8f4f-53990a133011",
   "metadata": {},
   "source": [
    "Create a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79be6a-aad1-4b46-973d-1112fe397127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# define the folder name\n",
    "folder=\"./PRISM_monthly_normals\"\n",
    "\n",
    "# check if the folder already exists or not\n",
    "if [ ! -d \"$folder\" ]; then\n",
    "    mkdir -p \"$folder\"\n",
    "    echo \"Directory created: $folder\"\n",
    "else\n",
    "    echo \"Directory already exists: $folder\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7de48-1ba1-4b7c-9bcd-cede82f097c9",
   "metadata": {},
   "source": [
    "#### Print the data links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18865861-a7bf-4f7c-b5e2-8288744687e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for m in {01..12};do\n",
    "    echo https://ftp.prism.oregonstate.edu/normals_800m/ppt/PRISM_ppt_30yr_normal_800mM4_${m}_bil.zip\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7ecad-904a-4010-9106-db3bc55f44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: work on this code.\n",
    "### For some reason it does not stop.\n",
    "\n",
    "# for some reason the following code never stops.\n",
    "# %%bash\n",
    "\n",
    "# m=1\n",
    "# while [[ $m -le 12 ]]; do\n",
    "#     month=$(printf \"%02d\" \"$m\")  # Format month with leading zero if needed\n",
    "#     echo \"Downloading data for Month: $month\"\n",
    "#     url=\"https://ftp.prism.oregonstate.edu/normals_800m/ppt/PRISM_ppt_30yr_normal_800mM4_${month}_bil.zip\"\n",
    "    \n",
    "#     # Use 'wget' to download the file using the generated URL\n",
    "#     wget \"$url\" -P ./PRISM_monthly_normals\n",
    "    \n",
    "#     sleep 4\n",
    "    \n",
    "#     # Increment the month\n",
    "#     m=$((m+1))\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21393000-d7b7-450f-ab4e-4274ed08f29b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try downloading each month manually\n",
    "!wget https://ftp.prism.oregonstate.edu/normals_800m/ppt/PRISM_ppt_30yr_normal_800mM4_01_bil.zip -P ./PRISM_monthly_normals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c630e7-cadc-4912-877d-f5a692ea2317",
   "metadata": {},
   "source": [
    "#### Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2b4252-d1f3-408f-bf8f-821e17153ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "folder=\"./PRISM_monthly_normals\"\n",
    "\n",
    "for file in \"$folder\"/*.zip; do\n",
    "    python -c \"import zipfile; zipfile.ZipFile('$file', 'r').extractall('$folder')\"  # unzip is not avail\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5224f5-d574-48e1-a8c7-3a91a47eab88",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualize one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b57d2a-d7f1-4536-b067-f15d606fb577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use rasterio to import the data as img\n",
    "with rio.open(\"./PRISM_monthly_normals/PRISM_ppt_30yr_normal_800mM4_01_bil.bil\") as src:\n",
    "    boundary = src.bounds\n",
    "    img_precip = src.read()\n",
    "    nodata = src.nodata\n",
    "\n",
    "print(img_precip[0].min(), img_precip[0].max())\n",
    "x1=((img_precip[0].max())-0)/5\n",
    "x2=x1*2\n",
    "x3=x1*3\n",
    "x4=x1*4\n",
    "print(x1, x2, x3, x4)\n",
    "    \n",
    "# plot\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.title(\"Precipitation\", size=16)\n",
    "cmap = colors.ListedColormap(['cyan', 'skyblue', 'deepskyblue', 'royalblue', 'navy'])\n",
    "cmap.set_under('w')\n",
    "# bounds=[0, x1, x2, x3, x4, img_precip[0].max()]\n",
    "bounds=[0, 50, 100, 200, 600, img_precip[0].max()]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "imgplot = plt.imshow(img_precip[0], cmap=cmap, norm=norm) \n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Precipitation (mm)', size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83069cc8-11fb-48f5-83d9-77077531cbb2",
   "metadata": {},
   "source": [
    "## 3. Use Consistent Projectinos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ce0b9-2b84-412b-bbe7-2b3363b5f9be",
   "metadata": {},
   "source": [
    "As is often the case with GIS, there is a need to have consistent projections. The following GDAL command examines the projection of this precipitation data. Note that this data is not yet projected, and it has only a geographic coordinate system. That is why the UNIT is \"Degree\", and the Pixel Size is 0.008333333333333 degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d98a9a-17e4-4c58-a728-b989be1c9c03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the stats of the PRISM data\n",
    "!gdalinfo -stats ./PRISM_monthly_normals/PRISM_ppt_30yr_normal_800mM4_01_bil.bil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd92d3-ff61-45d9-acff-e7f53ab050c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine the projection of the watershed\n",
    "!ogrinfo -al ./GISBasins/WeberRiverBasin.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e65124-8259-40c0-a2de-1326165c16d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use the information above in conjuction with the `gdalwrap` function to assign the projection of the shapefile to each of the PRISM files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7989771-9127-49da-812a-6aa48d1d8760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of all .bil files in the folder\n",
    "bil_files = [file for file in os.listdir(\"./PRISM_monthly_normals\") if file.endswith('.bil')]\n",
    "bil_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2500ff-5e2f-440e-82dc-3e2345887ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure the following folders exist in the current working directory\n",
    "input_folder = './PRISM_monthly_normals'  \n",
    "output_folder = './PRISM_monthly_normals/outputs'\n",
    "\n",
    "# Loop through each .bil file and use gdalwrap to covert the projection\n",
    "for bil_file in bil_files:\n",
    "    \n",
    "    # Specify the input and output file paths\n",
    "    input_file = os.path.join(input_folder, bil_file)\n",
    "    output_file = os.path.join(output_folder, bil_file)\n",
    "    \n",
    "    # Construct the gdalwarp command\n",
    "    gdalwarp_cmd = f'gdalwarp -overwrite -t_srs EPSG:4269 {input_file} {output_file}'\n",
    "    \n",
    "    # Execute the gdalwarp command using subprocess\n",
    "    subprocess.run(gdalwarp_cmd, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47977a93-a212-422f-b9f1-78b04a7aef11",
   "metadata": {},
   "source": [
    "## 4. Subset PRISM Data for the Watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78ecae-ee9d-4797-afcc-d0172ea8eb58",
   "metadata": {},
   "source": [
    "Use `zonal_stat` to compute the statistics of the PRISM data clipped for the watershed boundary. Note that we are interested in the `mean` values. Create a dataframe that contains dates and spatially averaged daily precipitation values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74647eec-6adb-4439-ad82-fe65a13fe20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of all .bil files in the folder\n",
    "bil_files = [file for file in os.listdir(\"./PRISM_monthly_normals/outputs\") if file.endswith('.bil')]\n",
    "print(bil_files)\n",
    "\n",
    "month=[]\n",
    "p=[]\n",
    "\n",
    "# Loop through each .bil file\n",
    "for bil_file in bil_files:\n",
    "\n",
    "    stats=zonal_stats(\"./GISBasins/WeberRiverBasin.shp\", f\"./PRISM_monthly_normals/outputs/{bil_file}\")\n",
    "    \n",
    "    month.append(int(bil_file.split(\"_\")[-2]))\n",
    "    \n",
    "    p.append(stats[0]['mean'])\n",
    "    \n",
    "df = pd.DataFrame({'Month': month, 'Precipitation (mm)': p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe171e3-81d0-4ed2-962e-177d950f989d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bce41bf-febd-4d95-a7ff-9d17a0d89b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort the dataframe based on dates\n",
    "df = df.sort_values(by='Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37f0de7d-d423-4fe2-a7d4-b0c809940a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the dataframe as a CSV file\n",
    "df.to_csv('./PRISM_monthly_normals/outputs/PRISM_Monthly_Normal_Precipitation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228b5e2-37e6-44a1-802c-0e0e65967a86",
   "metadata": {},
   "source": [
    "## 5. Plot the Precipitation Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aaadae-f58d-46e9-8f7a-3c0f35ff9518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "import matplotlib.pyplot as plt\n",
    "ax.plot(df['Month'], df['Precipitation (mm)'], color='b')\n",
    "ax.set_ylabel('Depth (mm)', size=18)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.set_title('PRISM monthly normals precipitation averaged across the watershed', size=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iguide]",
   "language": "python",
   "name": "conda-env-iguide-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
